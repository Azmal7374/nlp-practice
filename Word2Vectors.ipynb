{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8455925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1929ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba813f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp_df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac115b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cfc484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17028\\3006716147.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711c5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826ef270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17028\\740760900.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(lambda x:x.lower())\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1adeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17028\\3841627977.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw_list = stopwords.words('english')\n",
    "df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fff0e6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       one reviewers mentioned watching 1 oz episode ...\n",
       "1       wonderful little production. <br /><br />the f...\n",
       "2       thought wonderful way spend time hot summer we...\n",
       "3       basically there's family little boy (jake) thi...\n",
       "4       petter mattei's \"love time money\" visually stu...\n",
       "                              ...                        \n",
       "9995    fun, entertaining movie wwii german spy (julie...\n",
       "9996    give break. anyone say \"good hockey movie\"? kn...\n",
       "9997    movie bad movie. watching endless series bad h...\n",
       "9998    movie probably made entertain middle school, e...\n",
       "9999    smashing film film-making. shows intense stran...\n",
       "Name: review, Length: 9983, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348bacd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c12f3",
   "metadata": {},
   "source": [
    "**You've imported the gensim library, which is a popular library for natural language processing and text analysis tasks, particularly for working with word embeddings and topic modeling. gensim provides tools for training and using word embeddings like Word2Vec and Doc2Vec, as well as functions for topic modeling with methods like Latent Dirichlet Allocation (LDA).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c845f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a844f1",
   "metadata": {},
   "source": [
    "1. sent_tokenize from NLTK:\n",
    "   * sent_tokenize is used for sentence tokenization, which means breaking a text into individual sentences.\n",
    "    * It takes a block of text as input and returns a list of sentences.\n",
    "    \n",
    "2. simple_preprocess from gensim:\n",
    "   * simple_preprocess is a utility function for text preprocessing that performs basic preprocessing steps such as tokenization, lowercasing, and removing punctuation.\n",
    "    * It takes a string as input and returns a list of preprocessed tokens (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0436c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = []\n",
    "for doc in df['review']:\n",
    "    raw_sent = sent_tokenize(doc)\n",
    "    for sent in raw_sent:\n",
    "        story.append(simple_preprocess(sent))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba13563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7effc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83ee5e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5935553, 6424740)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3d9f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31846"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3db9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c15d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2410262 ,  0.34991115,  0.07217623,  0.03344386,  0.01770463,\n",
       "       -0.59102666,  0.20887274,  0.9412403 , -0.05803785, -0.17358612,\n",
       "       -0.07372425, -0.55649364,  0.00865161,  0.3903537 ,  0.05299453,\n",
       "       -0.29992655,  0.13905257, -0.33307177, -0.0268338 , -0.6186111 ,\n",
       "       -0.06469975,  0.09567872,  0.3057215 , -0.06521441,  0.054617  ,\n",
       "       -0.02705205, -0.27546784, -0.25594318, -0.34188765,  0.03586407,\n",
       "        0.31191364, -0.01321147,  0.21706605, -0.41404295, -0.08733148,\n",
       "        0.42363793, -0.00166671, -0.3188812 , -0.30863345, -0.78469664,\n",
       "       -0.24822423, -0.07277132, -0.11642195,  0.09557318,  0.5143803 ,\n",
       "       -0.208121  , -0.27382684, -0.06578827,  0.11419652,  0.10689662,\n",
       "        0.09756421, -0.37686628, -0.31044698, -0.06043475, -0.09358449,\n",
       "        0.09896173,  0.31208342,  0.04872354, -0.38573456,  0.11380082,\n",
       "       -0.02272581,  0.0786477 ,  0.00750763,  0.07119747, -0.47490755,\n",
       "        0.21638776,  0.05755654,  0.26009113, -0.5586753 ,  0.56410325,\n",
       "       -0.14379077,  0.2744618 ,  0.01028971, -0.06464539,  0.41973907,\n",
       "       -0.02501759,  0.19818656, -0.31794322, -0.23277625,  0.15015294,\n",
       "       -0.31910893, -0.02950158, -0.42881805,  0.47821602, -0.12773032,\n",
       "        0.16563666, -0.01718522,  0.24224883,  0.37357065,  0.243114  ,\n",
       "        0.30295962,  0.05240214, -0.03829722,  0.3925482 ,  0.5252356 ,\n",
       "        0.19700001,  0.17903094, -0.1761483 ,  0.07501116, -0.10425274],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector(df['review'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94ad9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fe74f",
   "metadata": {},
   "source": [
    "**You've imported the tqdm library, which is a popular library for adding progress bars to loops and iterations in Python. The name \"tqdm\" stands for \"taqaddum\" in Arabic, which means \"progress.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddb0852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9983/9983 [13:34<00:00, 12.26it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for doc in tqdm(df['review'].values):\n",
    "    X.append(document_vector(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd1d19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94c47dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2410262 ,  0.34991115,  0.07217623,  0.03344386,  0.01770463,\n",
       "       -0.59102666,  0.20887274,  0.9412403 , -0.05803785, -0.17358612,\n",
       "       -0.07372425, -0.55649364,  0.00865161,  0.3903537 ,  0.05299453,\n",
       "       -0.29992655,  0.13905257, -0.33307177, -0.0268338 , -0.6186111 ,\n",
       "       -0.06469975,  0.09567872,  0.3057215 , -0.06521441,  0.054617  ,\n",
       "       -0.02705205, -0.27546784, -0.25594318, -0.34188765,  0.03586407,\n",
       "        0.31191364, -0.01321147,  0.21706605, -0.41404295, -0.08733148,\n",
       "        0.42363793, -0.00166671, -0.3188812 , -0.30863345, -0.78469664,\n",
       "       -0.24822423, -0.07277132, -0.11642195,  0.09557318,  0.5143803 ,\n",
       "       -0.208121  , -0.27382684, -0.06578827,  0.11419652,  0.10689662,\n",
       "        0.09756421, -0.37686628, -0.31044698, -0.06043475, -0.09358449,\n",
       "        0.09896173,  0.31208342,  0.04872354, -0.38573456,  0.11380082,\n",
       "       -0.02272581,  0.0786477 ,  0.00750763,  0.07119747, -0.47490755,\n",
       "        0.21638776,  0.05755654,  0.26009113, -0.5586753 ,  0.56410325,\n",
       "       -0.14379077,  0.2744618 ,  0.01028971, -0.06464539,  0.41973907,\n",
       "       -0.02501759,  0.19818656, -0.31794322, -0.23277625,  0.15015294,\n",
       "       -0.31910893, -0.02950158, -0.42881805,  0.47821602, -0.12773032,\n",
       "        0.16563666, -0.01718522,  0.24224883,  0.37357065,  0.243114  ,\n",
       "        0.30295962,  0.05240214, -0.03829722,  0.3925482 ,  0.5252356 ,\n",
       "        0.19700001,  0.17903094, -0.1761483 ,  0.07501116, -0.10425274],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ce2af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d723e86",
   "metadata": {},
   "source": [
    "**You've imported the LabelEncoder class from scikit-learn's preprocessing module. LabelEncoder is a useful tool for preprocessing categorical labels in your dataset by converting them into numerical values. It assigns a unique integer to each category in your data, making it suitable for various machine learning algorithms that require numeric input for labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38757296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54c316f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de416d90",
   "metadata": {},
   "source": [
    " **You've imported the train_test_split function from scikit-learn's model_selection module. train_test_split is a fundamental function used in machine learning to split your dataset into training and testing sets. This division allows you to train your model on one subset of the data and evaluate its performance on another, unseen subset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "932572c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f2e8b",
   "metadata": {},
   "source": [
    "**1.  RandomForestClassifier: This is a class from the sklearn's ensemble module, and it represents the Random Forest classifier, which is an ensemble learning method for classification tasks. Random Forest is known for its robustness and ability to handle both categorical and numerical features.**\n",
    "\n",
    "**2.  accuracy_score: This is a function from the metrics module in sklearn. It's used to calculate the accuracy of your classification model, which measures the fraction of correctly predicted labels.After making predictions with your classifier, you can use accuracy_score to evaluate its performance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "166edc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7746619929894842"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823300a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
