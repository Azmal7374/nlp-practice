{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80fe09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc310180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['omw-1.4.zip', 'stopwords', 'stopwords.zip', 'wordnet.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90dbcf3",
   "metadata": {},
   "source": [
    "# NLTK, short for Natural Language Toolkit, is a Python library designed to work with human language data. It provides easy-to-use interfaces and resources for working with and analyzing text data. NLTK is widely used for educational purposes, research, and practical NLP applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a42782",
   "metadata": {},
   "source": [
    "#### 1. **Text Processing:** NLTK provides tools for tokenization (splitting text into words or sentences), stemming (reducing words to their root form), and lemmatization (reducing words to their base or dictionary form).\n",
    "\n",
    "#### 2. **Part-of-Speech Tagging:** NLTK includes pre-trained models for part-of-speech tagging, which involves labeling words in a sentence with their grammatical parts of speech (e.g., noun, verb, adjective).\n",
    "\n",
    "#### 3. **Named Entity Recognition (NER):** It offers named entity recognition tools that can identify entities such as names of people, organizations, locations, and more within text.\n",
    "\n",
    "#### 4. **Sentiment Analysis:** NLTK includes resources for sentiment analysis, allowing you to determine the sentiment (positive, negative, neutral) of a piece of text.\n",
    "\n",
    "#### 5. **Corpora and Lexical Resources:** NLTK provides access to various corpora (collections of text) and lexical resources (dictionaries, word lists) that are useful for linguistic analysis and research.\n",
    "\n",
    "#### 6. **Text Classification:** It supports text classification tasks, making it suitable for tasks like spam email detection, sentiment classification, and more.\n",
    "\n",
    "#### 7. **Language Processing Pipelines:** NLTK allows you to build processing pipelines for various NLP tasks, making it flexible for custom NLP workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0f1f8",
   "metadata": {},
   "source": [
    "# 1. Tokenization:\n",
    "**Tokenization is the process of splitting text into words or sentences. NLTK provides tools for both word and sentence tokenization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e06822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "['NLTK is a powerful library for natural language processing.', 'It is widely used in research and education.']\n",
      "\n",
      "Words:\n",
      "['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', '.', 'It', 'is', 'widely', 'used', 'in', 'research', 'and', 'education', '.']\n",
      "['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', '.', 'It', 'is', 'widely', 'used', 'in', 'research', 'and', 'education', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"NLTK is a powerful library for natural language processing. It is widely used in research and education.\"\n",
    "\n",
    "# Tokenize the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "print(\"Sentences:\")\n",
    "print(sentences)\n",
    "print(\"\\nWords:\")\n",
    "print(words)\n",
    "print(words)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94c66f",
   "metadata": {},
   "source": [
    "# 2. Part-of-Speech (POS) Tagging:\n",
    "**NLTK can identify the grammatical parts of speech for words in a sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15701c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     path_to_download_directory...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger', download_dir='path_to_download_directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f191ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part-of-Speech Tags:\n",
      "[('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('library', 'NN'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "text = \"NLTK is a powerful library for natural language processing.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "print(\"Part-of-Speech Tags:\")\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e071ccf",
   "metadata": {},
   "source": [
    "# 3. Named Entity Recognition (NER):\n",
    "**NLTK can recognize named entities such as names of people, organizations, locations, and more.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c14dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     path_to_download_directory...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('maxent_ne_chunker', download_dir='path_to_download_directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e35c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n",
      "[nltk_data] Downloading package words to path_to_download_directory...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('words', download_dir='path_to_download_directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7814e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Recognition Tags:\n",
      "(S\n",
      "  (PERSON Apple/NNP)\n",
      "  (ORGANIZATION Inc./NNP)\n",
      "  is/VBZ\n",
      "  headquartered/VBN\n",
      "  in/IN\n",
      "  (GPE Cupertino/NNP)\n",
      "  ,/,\n",
      "  (GPE California/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple Inc. is headquartered in Cupertino, California.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "# Perform named entity recognition (NER)\n",
    "ner_tags = nltk.ne_chunk(nltk.pos_tag(words))\n",
    "\n",
    "print(\"Named Entity Recognition Tags:\")\n",
    "print(ner_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187ef9d",
   "metadata": {},
   "source": [
    "# 4. Sentiment Analysis:\n",
    "**NLTK provides resources for performing sentiment analysis to determine the sentiment of a piece of text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b5fcd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     path_to_download_directory...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('vader_lexicon', download_dir='path_to_download_directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2df77cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Scores:\n",
      "{'neg': 0.0, 'neu': 0.496, 'pos': 0.504, 'compound': 0.7269}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Sample text\n",
    "text = \"NLTK is a fantastic library for natural language processing.\"\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze the sentiment of the text\n",
    "sentiment_scores = analyzer.polarity_scores(text)\n",
    "\n",
    "print(\"Sentiment Analysis Scores:\")\n",
    "print(sentiment_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27876388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
